<!DOCTYPE html>

<html>

<head>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="css/fonts.css">
  <link rel="stylesheet" type="text/css" href="css/demo.css">
  <link rel="stylesheet" type="text/css" href="css/highlightGen.css">
  <title>Demo</title>
</head>


<body>

<header>
  <nav>
    <ul>
      <li><a href="index.html">HOME</a></li>
    </ul>
  </nav>
</header>

<section id="Landing">
  <label>
    <h2 class="videoHeading">Source Video and Generated Highlights</h2>
    <div class="icon"></div>
  </label>
  <div class="videoContainer" style="background-image: url(photos/fv_shots.png)">
      <iframe width="560" height="315" src="https://www.youtube.com/embed/MFMeskzDQX8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
  </div>
  <div class="videoContainer" style="background-image: url(photos/high_shots.png)">
      <iframe width="560" height="315" src="https://www.youtube.com/embed/2_WzahZ1NrA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
  </div>
</section>

<section id="lightbox">
  <div id="content">
    <div id="cross"></div>


<div id="textContained">
<br>
<p>
  <h2>Highlights generation of Soccer Matches</h2><br>
  Project Areas: Computer Vision, Image Processing, Audio Processing, Machine Learning, Object Detection.
</p>
<br><br>
<p>
  <h3>Aim:</h3>
  <ul>
    <li>The aim of this project is to automate the process of generating highlights of a  match using machine learning.</li>
    <li>Highlights are at times more important than the match itself because most would not have the time to watch the whole match and would rather prefer to watch the important parts of a match. </li>
</p>

<br><br>
<p>
  <h3>Shot Boundary Detection:</h3>
  <ul>
    <li>Shot Boundary detection is used to split the input video into its constituent shots.</li>
    <li>Chi-squared algorithm has been implemented for shot boundary detection in OpenCV as it is good for detecting hard cuts in videos.</li>
</p>

<br><br>
<p>
  <h3>Dataset Creation:</h3>
  <ul>
    <li>We downloaded 4 soccer match videos of varying lengths and ran the shot detector algorithm to split them into constituent shots. The number of shots amassed to 800. These shots were classified as highlights and non-highlights manually. We ended up with a 3:1 ratio of negatives to positives. Later, we extracted audio from the shots and created separate corresponding audio files using ffmpeg.</li>
</p>

<br><br>
<p>
  <h3>Audio Feature Extraction:</h3>
  <ul>
    <li>PyAudioAnalysis is being used for extracting audio features as it gives 34 relevant features for a single audio file including MFCC features and audio amplitude.</li>
  </ul>
</p>

<br><br>
<p>
  <h3>Object Detection:</h3>
  <ul>
    <li>For visual features, the ball and goalposts were detected in frames by training different tensorflow object detection models.</li>
    <li>We used 3 different models - Faster-RCNN with Inception, SSD Lite with MobileNet, SSD with Inception were tried.</li>
    <li>Finally, SSD Lite with Mobilenet was chosen because of its speed. </li>
  </ul>
</p>

<br><br>
<p>
  <h3>Visual Feature Computation:</h3>
  The following features have been computed over certain intervals of a shot:
  <ul>
    <li>a) Average Size of a Goalpost</li>
    <li>b) Percentage of frames in which Goalpost was detected</li>
    <li>c) Position of Goalpost</li>
  </ul>
</p>

<br><br>
<p>
  <h3>Prediction using Scikit-Learnâ€™s SVM:</h3>
  <ul>
    <li>Now for each shot in training dataset a feature vector comprising of audio and visual features as well as the shot duration was generated and this was trained on scikit-learn's object detection model.</li>
  </ul>
</p>

<br><br>
<p>
  <h3>Stitching the shots into highlights:</h3>
  <ul>
    <li>Given an input match video it was divided into shots and then for each shot its features were extracted and its probability of being a highlight was computed using the trained SVM model.</li>
    <li>Finally the shots with highest probability were added into output video as long as the probability was greater than 0.5 and the maximum length of output video was not exceeded.</li>
    <li>Selected Shots were stitched using MoviePy to generate the highlights.</li>
  </ul>
</p>

</div>
</div>
</section>

</body>
<script>
  document.querySelector(".icon").onclick = function() {
    lightbox.style.display = "flex";
  }
  cross.onclick = function(e) {
    lightbox.style.display = "";
  }
</script>
</html>
